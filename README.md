<!-- Gesture-Controlled Game Interface README -->

<p align="center">
  <img src="https://readme-typing-svg.herokuapp.com?font=Poppins&pause=1000&color=36BCF7&center=true&vCenter=true&width=900&lines=âœ‹ğŸ®+Gesture-Controlled+Game+Interface+using+Computer+Vision;Real-Time+Humanâ€“Computer+Interaction+System;OpenCV+%7C+MediaPipe+%7C+Python" alt="Typing Animation" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Status-Completed-success?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Domain-Computer%20Vision%20%7C%20HCI-blue?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Python-3.10-yellow?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Made%20withâ¤ï¸by-Priyanka%20Asthana-ff69b4?style=for-the-badge"/>
</p>

---

## ğŸ¥ Project Demo & Video Walkthrough (Start Here)

<p align="center">
  <a href="PUT_YOUR_VIDEO_LINK_HERE">
    <img src="https://img.shields.io/badge/â–¶%20Watch%20Full%20Project%20Demo-red?style=for-the-badge&logo=youtube"/>
  </a>
</p>

<p align="center">
  <sub><i>Complete walkthrough explaining system design, gesture logic, and real-time interaction pipeline.</i></sub>
</p>

---

## ğŸš€ Overview

This project implements a **real-time gesture-controlled gaming interface** using **computer vision and humanâ€“computer interaction (HCI)** principles.

Hand gestures captured through a webcam are processed live and translated into **system-level keyboard inputs**, enabling **hands-free control of a game** running inside an Android emulator.

The goal was not just gesture detection, but building a **robust end-to-end interaction pipeline** that connects vision, decision logic, and OS-level control in real time.

---

## ğŸ§  System Pipeline (High-Level)

Camera Input
   â†“
Hand Landmark Detection
   â†“
Gesture Classification
   â†“
Keyboard Event Mapping
   â†“
OS-Level Input Injection
   â†“
Game / Emulator Control
This pipeline is designed to be modular, extensible, and hardware-aware, making it suitable for experimentation with other applications beyond gaming.

## âœ¨ Key Features
Feature	Description
âœ‹ Real-Time Hand Tracking	Tracks hand landmarks live using MediaPipe via CVZone
ğŸ¯ Gesture-Based Control	Interprets finger states (open palm, fist) into actions
âŒ¨ï¸ System-Level Input	Injects keyboard events using Python (pynput)
ğŸ® External App Integration	Controls a game running in an Android emulator
âš¡ Low Latency Pipeline	Designed for smooth real-time interaction
ğŸ§ª Experiment-Friendly	Easy to extend with new gestures or applications

## ğŸ§° Tech Stack
<p align="center"> <img src="https://skillicons.dev/icons?i=python,opencv,git,vscode&theme=dark" /> </p>

## ğŸ§° Core Technologies

- **Python 3.10**
- **OpenCV** â€“ video capture and frame processing
- **MediaPipe** â€“ hand landmark detection
- **CVZone** â€“ abstraction over MediaPipe for gesture handling
- **pynput** â€“ OS-level keyboard event simulation

---

## ğŸ§­ System Architecture

```mermaid
graph TD
    A[Webcam Input] --> B[OpenCV Frame Processing]
    B --> C[MediaPipe Hand Landmarks]
    C --> D[Gesture Logic]
    D --> E[Keyboard Event Mapping]
    E --> F[OS-Level Input]
    F --> G[Game / Emulator]
```
    
## ğŸš€ Getting Started
<p>1ï¸âƒ£ Clone the Repository
bash
Copy code
git clone https://github.com/YOUR_USERNAME/gesture-controlled-game-interface.git
cd gesture-controlled-game-interface</p>
<p>2ï¸âƒ£ Create Virtual Environment
bash
Copy code
python -m venv venv
venv\Scripts\Activate   # Windows </p>
<p>3ï¸âƒ£ Install Dependencies
bash
Copy code
pip install -r requirements.txt</p>
<p>4ï¸âƒ£ Run the Project
bash
Copy code
python gesture_control_hill_climb.py</p>
âš ï¸ Make sure the game/emulator window is in focus while running the script.

## ğŸ§ª Gesture Mapping (Current)
<p>Gesture	Action </p>
<p>âœŠ Fist	Move Left ğŸ– Open Palm	Move Right</p>
<p>Other / No Hand	Neutral</p>


## ğŸ‘©â€ğŸ’» Author
Priyanka Asthana
<p>ğŸ“ B.Tech (Hons) CSE | Minor in Robotics</p>
<p>ğŸ“ India</p>
